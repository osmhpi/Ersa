{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Language Translation with ``nn.Transformer`` and torchtext\n",
    "\n",
    "This tutorial shows:\n",
    "    - How to train a translation model from scratch using Transformer.\n",
    "    - Use torchtext library to access  [Multi30k](http://www.statmt.org/wmt16/multimodal-task.html#task1)_ dataset to train a German to English translation model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sourcing and Processing\n",
    "\n",
    "[torchtext library](https://pytorch.org/text/stable/)_ has utilities for creating datasets that can be easily\n",
    "iterated through for the purposes of creating a language translation\n",
    "model. In this example, we show how to use torchtext's inbuilt datasets,\n",
    "tokenize a raw text sentence, build vocabulary, and numericalize tokens into tensor. We will use\n",
    "[Multi30k dataset from torchtext library](https://pytorch.org/text/stable/datasets.html#multi30k)_\n",
    "that yields a pair of source-target raw sentences.\n",
    "\n",
    "To access torchtext datasets, please install torchdata following instructions at https://github.com/pytorch/data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "import spacy\n",
    "\n",
    "\n",
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\n",
    "    \"train\"\n",
    "] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\n",
    "    \"valid\"\n",
    "] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = \"de\"\n",
    "TGT_LANGUAGE = \"en\"\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ersa.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>executing command `python -m spacy download en_core_web_sm` on remote host</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anyio==3.7.1', 'argon2-cffi==21.3.0', 'argon2-cffi-bindings==21.2.0', 'arrow==1.2.3', 'asttokens==2.2.1', 'async-lru==2.0.3', 'attrs==23.1.0', 'Babel==2.12.1', 'backcall==0.2.0', 'beautifulsoup4==4.12.2', 'bleach==6.0.0', 'blis==0.7.10', 'catalogue==2.0.9', 'certifi==2023.5.7', 'cffi==1.15.1', 'charset-normalizer==3.2.0', 'click==8.1.3', 'cmake==3.27.0', 'comm==0.1.3', 'confection==0.1.0', 'contourpy==1.1.0', 'cycler==0.11.0', 'cymem==2.0.7', 'Cython==3.0.0', 'de-core-news-sm @ https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0-py3-none-any.whl', 'debugpy==1.6.7', 'decorator==5.1.1', 'defusedxml==0.7.1', 'dill==0.3.6', 'en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl', 'exceptiongroup==1.1.2', 'executing==1.2.0', 'fastjsonschema==2.17.1', 'filelock==3.12.2', 'fonttools==4.41.1', 'fqdn==1.5.1', 'idna==3.4', 'ipykernel==6.22.0', 'ipython==8.13.1', 'ipython-genutils==0.2.0', 'ipywidgets==8.0.7', 'isoduration==20.11.0', 'jedi==0.18.2', 'Jinja2==3.1.2', 'json5==0.9.14', 'jsonpointer==2.4', 'jsonschema==4.18.4', 'jsonschema-specifications==2023.7.1', 'jupyter==1.0.0', 'jupyter-console==6.6.3', 'jupyter-events==0.6.3', 'jupyter-lsp==2.2.0', 'jupyter_client==8.3.0', 'jupyter_core==5.3.1', 'jupyter_server==2.7.0', 'jupyter_server_terminals==0.4.4', 'jupyterlab==4.0.3', 'jupyterlab-pygments==0.2.2', 'jupyterlab-widgets==3.0.8', 'jupyterlab_server==2.23.0', 'kiwisolver==1.4.4', 'langcodes==3.3.0', 'lit==16.0.6', 'MarkupSafe==2.1.3', 'matplotlib==3.7.2', 'matplotlib-inline==0.1.6', 'megaclite==0.0.2', 'mistune==3.0.1', 'mpmath==1.3.0', 'murmurhash==1.0.9', 'nbclient==0.8.0', 'nbconvert==7.7.2', 'nbformat==5.9.1', 'nest-asyncio==1.5.6', 'networkx==3.1', 'notebook==7.0.0', 'notebook_shim==0.2.3', 'numpy==1.25.1', 'nvidia-cublas-cu11==11.10.3.66', 'nvidia-cuda-cupti-cu11==11.7.101', 'nvidia-cuda-nvrtc-cu11==11.7.99', 'nvidia-cuda-runtime-cu11==11.7.99', 'nvidia-cudnn-cu11==8.5.0.96', 'nvidia-cufft-cu11==10.9.0.58', 'nvidia-curand-cu11==10.2.10.91', 'nvidia-cusolver-cu11==11.4.0.1', 'nvidia-cusparse-cu11==11.7.4.91', 'nvidia-nccl-cu11==2.14.3', 'nvidia-nvtx-cu11==11.7.91', 'overrides==7.3.1', 'packaging==23.1', 'pandocfilters==1.5.0', 'parso==0.8.3', 'pathy==0.10.2', 'pexpect==4.8.0', 'pickleshare==0.7.5', 'Pillow==10.0.0', 'pip==22.2.1', 'platformdirs==3.9.1', 'preshed==3.0.8', 'prometheus-client==0.17.1', 'prompt-toolkit==3.0.39', 'psutil==5.9.5', 'ptyprocess==0.7.0', 'pure-eval==0.2.2', 'pycocotools @ git+https://github.com/cocodataset/cocoapi.git@8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9#subdirectory=PythonAPI', 'pycparser==2.21', 'pydantic==1.10.12', 'Pygments==2.15.1', 'pyparsing==3.0.9', 'python-dateutil==2.8.2', 'python-json-logger==2.0.7', 'PyYAML==6.0.1', 'pyzmq==25.1.0', 'qtconsole==5.4.3', 'QtPy==2.3.1', 'referencing==0.30.0', 'requests==2.31.0', 'rfc3339-validator==0.1.4', 'rfc3986-validator==0.1.1', 'rpds-py==0.9.2', 'Send2Trash==1.8.2', 'setuptools==63.2.0', 'six==1.16.0', 'smart-open==6.3.0', 'sniffio==1.3.0', 'soupsieve==2.4.1', 'spacy==3.6.0', 'spacy-legacy==3.0.12', 'spacy-loggers==1.0.4', 'srsly==2.4.7', 'stack-data==0.6.2', 'sympy==1.12', 'terminado==0.17.1', 'thinc==8.1.10', 'tinycss2==1.2.1', 'tomli==2.0.1', 'torch==2.0.1', 'torchdata==0.6.1', 'torchtext==0.15.2', 'torchvision==0.15.2', 'tornado==6.3.2', 'tqdm==4.65.0', 'traitlets==5.9.0', 'triton==2.0.0', 'typer==0.9.0', 'typing_extensions==4.7.1', 'uri-template==1.3.0', 'urllib3==2.0.4', 'wasabi==1.1.2', 'wcwidth==0.2.6', 'webcolors==1.13', 'webencodings==0.5.1', 'websocket-client==1.6.1', 'wheel==0.40.0', 'widgetsnbextension==4.0.8']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<i>You are number 1 in the queue.<i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mrun_remote\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpython -m spacy download en_core_web_sm\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mrun_remote\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpython -m spacy download de_core_news_sm\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2419\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/megaclite/client.py:98\u001b[0m, in \u001b[0;36mRemoteTrainingMagics.run_remote\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     96\u001b[0m job \u001b[39m=\u001b[39m BashJob(command\u001b[39m=\u001b[39mline, client\u001b[39m=\u001b[39mcollect_client_info())\n\u001b[1;32m     97\u001b[0m \u001b[39mprint\u001b[39m(job\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mpackages)\n\u001b[0;32m---> 98\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_job(job\u001b[39m=\u001b[39;49mjob)\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/megaclite/client.py:44\u001b[0m, in \u001b[0;36mRemoteTrainingMagics.send_job\u001b[0;34m(self, job, on_success)\u001b[0m\n\u001b[1;32m     41\u001b[0m conn \u001b[39m=\u001b[39m Client(address)\n\u001b[1;32m     42\u001b[0m conn\u001b[39m.\u001b[39msend(job)\n\u001b[0;32m---> 44\u001b[0m \u001b[39mwhile\u001b[39;00m message \u001b[39m:=\u001b[39m conn\u001b[39m.\u001b[39;49mrecv():\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(message, JobInfo):\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m message\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m JobState\u001b[39m.\u001b[39mPENDING:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/connection.py:255\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 255\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    256\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    420\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    385\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run_remote python -m spacy download en_core_web_sm\n",
    "%run_remote python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create source and target language tokenizer. Make sure to install the dependencies.\n",
    "\n",
    "```python\n",
    "pip install -U torchdata\n",
    "pip install -U spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download de_core_news_sm\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Package `portalocker` is required to be installed to use this datapipe.Please use `pip install 'portalocker>=2.0.0'` or`conda install -c conda-forge 'portalocker>=2/0.0'`to install the package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/.venv/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:38\u001b[0m, in \u001b[0;36m_assert_portalocker\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mportalocker\u001b[39;00m  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'portalocker'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m special_symbols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m<unk>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<bos>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<eos>\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m ln \u001b[39min\u001b[39;00m [SRC_LANGUAGE, TGT_LANGUAGE]:\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Training data Iterator\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     train_iter \u001b[39m=\u001b[39m Multi30k(split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, language_pair\u001b[39m=\u001b[39;49m(SRC_LANGUAGE, TGT_LANGUAGE))\n\u001b[1;32m     20\u001b[0m     \u001b[39m# Create torchtext's Vocab object\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     vocab_transform[ln] \u001b[39m=\u001b[39m build_vocab_from_iterator(yield_tokens(train_iter, ln),\n\u001b[1;32m     22\u001b[0m                                                     min_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     23\u001b[0m                                                     specials\u001b[39m=\u001b[39mspecial_symbols,\n\u001b[1;32m     24\u001b[0m                                                     special_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/.venv/lib/python3.10/site-packages/torchtext/data/datasets_utils.py:193\u001b[0m, in \u001b[0;36m_create_dataset_directory.<locals>.decorator.<locals>.wrapper\u001b[0;34m(root, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(new_root):\n\u001b[1;32m    192\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(new_root, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m fn(root\u001b[39m=\u001b[39;49mnew_root, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/.venv/lib/python3.10/site-packages/torchtext/data/datasets_utils.py:155\u001b[0m, in \u001b[0;36m_wrap_split_argument_with_fn.<locals>.new_fn\u001b[0;34m(root, split, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m    154\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m _check_default_set(split, splits, fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m     result\u001b[39m.\u001b[39mappend(fn(root, item, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m _wrap_datasets(\u001b[39mtuple\u001b[39m(result), split)\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/.venv/lib/python3.10/site-packages/torchtext/datasets/multi30k.py:94\u001b[0m, in \u001b[0;36mMulti30k\u001b[0;34m(root, split, language_pair)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     89\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPackage `torchdata` not found. Please install following instructions at https://github.com/pytorch/data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     92\u001b[0m url_dp \u001b[39m=\u001b[39m IterableWrapper([URL[split]])\n\u001b[0;32m---> 94\u001b[0m cache_compressed_dp \u001b[39m=\u001b[39m url_dp\u001b[39m.\u001b[39;49mon_disk_cache(\n\u001b[1;32m     95\u001b[0m     filepath_fn\u001b[39m=\u001b[39;49mpartial(_filepath_fn, root, split),\n\u001b[1;32m     96\u001b[0m     hash_dict\u001b[39m=\u001b[39;49m{_filepath_fn(root, split): MD5[split]},\n\u001b[1;32m     97\u001b[0m     hash_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msha256\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m cache_compressed_dp \u001b[39m=\u001b[39m HttpReader(cache_compressed_dp)\u001b[39m.\u001b[39mend_caching(mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m, same_filepath_fn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    101\u001b[0m cache_compressed_dp_1, cache_compressed_dp_2 \u001b[39m=\u001b[39m cache_compressed_dp\u001b[39m.\u001b[39mfork(num_instances\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/.venv/lib/python3.10/site-packages/torch/utils/data/datapipes/datapipe.py:139\u001b[0m, in \u001b[0;36mIterDataPipe.register_datapipe_as_function.<locals>.class_function\u001b[0;34m(cls, enable_df_api_tracing, source_dp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclass_function\u001b[39m(\u001b[39mcls\u001b[39m, enable_df_api_tracing, source_dp, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 139\u001b[0m     result_pipe \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(source_dp, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result_pipe, IterDataPipe):\n\u001b[1;32m    141\u001b[0m         \u001b[39mif\u001b[39;00m enable_df_api_tracing \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(source_dp, DFIterDataPipe):\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/.venv/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:207\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__init__\u001b[0;34m(self, source_datapipe, filepath_fn, hash_dict, hash_type, extra_check_fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    201\u001b[0m     source_datapipe: IterDataPipe,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     extra_check_fn: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    206\u001b[0m ):\n\u001b[0;32m--> 207\u001b[0m     _assert_portalocker()\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe \u001b[39m=\u001b[39m source_datapipe\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m filepath_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/uni/phd/kisz/megaclite/.venv/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py:47\u001b[0m, in \u001b[0;36m_assert_portalocker\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPackage `portalocker` is required to be installed to use this datapipe.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use `pip install \u001b[39m\u001b[39m'\u001b[39m\u001b[39mportalocker>=2.0.0\u001b[39m\u001b[39m'\u001b[39m\u001b[39m` or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`conda install -c conda-forge \u001b[39m\u001b[39m'\u001b[39m\u001b[39mportalocker>=2/0.0\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto install the package\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: Package `portalocker` is required to be installed to use this datapipe.Please use `pip install 'portalocker>=2.0.0'` or`conda install -c conda-forge 'portalocker>=2/0.0'`to install the package"
     ]
    }
   ],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer(\"spacy\", language=\"de_core_news_sm\")\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(\n",
    "        yield_tokens(train_iter, ln),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )\n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Network using Transformer\n",
    "\n",
    "Transformer is a Seq2Seq model introduced in [“Attention is all you\n",
    "need”](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)_\n",
    "paper for solving machine translation tasks.\n",
    "Below, we will create a Seq2Seq network that uses Transformer. The network\n",
    "consists of three parts. First part is the embedding layer. This layer converts tensor of input indices\n",
    "into corresponding tensor of input embeddings. These embedding are further augmented with positional\n",
    "encodings to provide position information of input tokens to the model. The second part is the\n",
    "actual [Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)_ model.\n",
    "Finally, the output of the Transformer model is passed through linear layer\n",
    "that gives unnormalized probabilities for each token in the target language.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(-torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(\n",
    "            token_embedding + self.pos_embedding[: token_embedding.size(0), :]\n",
    "        )\n",
    "\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers: int,\n",
    "        num_decoder_layers: int,\n",
    "        emb_size: int,\n",
    "        nhead: int,\n",
    "        src_vocab_size: int,\n",
    "        tgt_vocab_size: int,\n",
    "        dim_feedforward: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: Tensor,\n",
    "        trg: Tensor,\n",
    "        src_mask: Tensor,\n",
    "        tgt_mask: Tensor,\n",
    "        src_padding_mask: Tensor,\n",
    "        tgt_padding_mask: Tensor,\n",
    "        memory_key_padding_mask: Tensor,\n",
    "    ):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(\n",
    "            src_emb,\n",
    "            tgt_emb,\n",
    "            src_mask,\n",
    "            tgt_mask,\n",
    "            None,\n",
    "            src_padding_mask,\n",
    "            tgt_padding_mask,\n",
    "            memory_key_padding_mask,\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we need a subsequent word mask that will prevent the model from looking into\n",
    "the future words when making predictions. We will also need masks to hide\n",
    "source and target padding tokens. Below, let's define a function that will take care of both.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the parameters of our model and instantiate the same. Below, we also\n",
    "define our loss function which is the cross-entropy loss and the optimizer used for training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(\n",
    "    NUM_ENCODER_LAYERS,\n",
    "    NUM_DECODER_LAYERS,\n",
    "    EMB_SIZE,\n",
    "    NHEAD,\n",
    "    SRC_VOCAB_SIZE,\n",
    "    TGT_VOCAB_SIZE,\n",
    "    FFN_HID_DIM,\n",
    ")\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collation\n",
    "\n",
    "As seen in the ``Data Sourcing and Processing`` section, our data iterator yields a pair of raw strings.\n",
    "We need to convert these string pairs into the batched tensors that can be processed by our ``Seq2Seq`` network\n",
    "defined previously. Below we define our collate function that converts a batch of raw strings into batch tensors that\n",
    "can be fed directly into our model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat(\n",
    "        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX]))\n",
    "    )\n",
    "\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(\n",
    "        token_transform[ln],  # Tokenization\n",
    "        vocab_transform[ln],  # Numericalization\n",
    "        tensor_transform,\n",
    "    )  # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define training and evaluation loop that will be called for each\n",
    "epoch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_dataloader = DataLoader(\n",
    "        train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            src, tgt_input\n",
    "        )\n",
    "\n",
    "        logits = model(\n",
    "            src,\n",
    "            tgt_input,\n",
    "            src_mask,\n",
    "            tgt_mask,\n",
    "            src_padding_mask,\n",
    "            tgt_padding_mask,\n",
    "            src_padding_mask,\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = Multi30k(split=\"valid\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            src, tgt_input\n",
    "        )\n",
    "\n",
    "        logits = model(\n",
    "            src,\n",
    "            tgt_input,\n",
    "            src_mask,\n",
    "            tgt_mask,\n",
    "            src_padding_mask,\n",
    "            tgt_padding_mask,\n",
    "            src_padding_mask,\n",
    "        )\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingredients to train our model. Let's do it!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "NUM_EPOCHS = 18\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print(\n",
    "        (\n",
    "            f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
    "            f\"Epoch time = {(end_time - start_time):.3f}s\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(\n",
    "            DEVICE\n",
    "        )\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    return (\n",
    "        \" \".join(\n",
    "            vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))\n",
    "        )\n",
    "        .replace(\"<bos>\", \"\")\n",
    "        .replace(\"<eos>\", \"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Attention is all you need paper.\n",
    "   https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
    "2. The annotated transformer. https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
